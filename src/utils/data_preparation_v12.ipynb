{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T22:24:58.986384019Z",
     "start_time": "2023-06-27T22:24:54.093127566Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch  # because we save the data as torch tensors\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wfdb # needed to read the format of the raw files\n",
    "from joblib import Parallel, delayed # to parallelize processing the ECGs, so that it all runs faster\n",
    "# info: in parallel mode print-statements are ignored. That is why functions that are run parallel should instead return a message\n",
    "import itertools # to flatten list of lists\n",
    "import resampy # to resample the ECGs\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "import config\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# create all necessary out-folders that are needed\n",
    "set_pieces_folders = [] # the foldernames where the cropped pieces of train-val-test are saved\n",
    "set_df_pathnames = [] # where the metadata-files for train-val-test are stored\n",
    "for set in config.SPLIT_NAMES:\n",
    "    set_pieces_folders.append(os.path.join(config.PIECES_FOLDER, set + f'_pieces_length_{config.PIECE_LENGTH}'))\n",
    "    set_df_pathnames.append(os.path.join(config.OUT_FOLDER, set + '_df.csv'))\n",
    "\n",
    "folders_to_create = set_pieces_folders + [config.OUT_FOLDER, config.DATALOADER_FOLDER, config.PIECES_FOLDER, config.EXTRACTED_ECGS_FOLDER]\n",
    "for folder in folders_to_create:\n",
    "    if not os.path.exists(folder):\n",
    "        Path(folder).mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T22:24:59.005400404Z",
     "start_time": "2023-06-27T22:24:58.986878309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading existing metadata file took 0.01772451400756836 seconds\n"
     ]
    }
   ],
   "source": [
    "# this block took ~10min (is faster when some files were already created before)\n",
    "use_parallel = True # set to false for debugging\n",
    "\n",
    "global_avg_val = 0 # global mean of alle signals, is substracted from the crops for the xresnet. Edit: this value is very close to 0, probably does not matter at all\n",
    "# - thus removed it\n",
    "\n",
    "\n",
    "def extract_clean_and_resample_signal(record, channel, orignal_frequency, file_id_num):\n",
    "    ECG_signal = []\n",
    "    nan_counter = 0\n",
    "    for signal in record.p_signal:\n",
    "        # signal contains just ONE sample of each channel\n",
    "        # device 0 has channels ECG1, ECG2 and NIBP\n",
    "        # device 1 has channels ECG1 and NIBP\n",
    "        # we ignore NIBP (Non-invasive blood-pressure measurement) and only chose one ECG channel\n",
    "\n",
    "        # remove NaN-values from array --> otherwise resampling may have issues\n",
    "        one_val = signal[channel]\n",
    "        if not np.isnan(one_val):\n",
    "            ECG_signal.append(one_val)\n",
    "        else:\n",
    "            nan_counter += 1\n",
    "    # make an array out of the ECG signal\n",
    "    ecg_array = np.array([ECG_signal]) # dimensions: (1, record-length)\n",
    "    if config.RESAMPLE_TO > 0:\n",
    "        ecg_array = resampy.resample(ecg_array, orignal_frequency, config.RESAMPLE_TO)\n",
    "    ecg_array = torch.tensor(ecg_array)\n",
    "    return ecg_array, nan_counter\n",
    "\n",
    "def read_and_extract_signal(row):\n",
    "    # construct the correct path\n",
    "    file_id_num = int(row.iloc[0]['ID'])\n",
    "    filename = str(file_id_num).zfill(4) # respect leading zeros: 186 ---> 0186\n",
    "    filepathname = os.path.join(config.SOURCE_FOLDER, filename)\n",
    "    tensor_file_pathname = os.path.join(config.EXTRACTED_ECGS_FOLDER, filename + '.pt')\n",
    "    need_to_drop_this_row = False\n",
    "    message = ''\n",
    "    avg_val = 0\n",
    "    nan_counter = 0\n",
    "\n",
    "    if not os.path.exists(tensor_file_pathname): # if it already exists, there is no need to create it again\n",
    "        try:\n",
    "            record_content = wfdb.rdrecord(filepathname)\n",
    "            device_number = row.iloc[0]['Device']\n",
    "            orignal_frequency = record_content.fs\n",
    "            \n",
    "            # only extract one certain lead\n",
    "            if (device_number == 0) or (device_number == 1):\n",
    "                \n",
    "                if device_number == 0: # device 0 has 2 lead ECGs, only the second is comparable to the 1 lead from device 1\n",
    "                    ECG_signal_array, nan_counter = extract_clean_and_resample_signal(record_content, 1, orignal_frequency, file_id_num)\n",
    "                elif device_number == 1:\n",
    "                    ECG_signal_array, nan_counter = extract_clean_and_resample_signal(record_content, 0, orignal_frequency, file_id_num)               \n",
    "                \n",
    "                torch.save(ECG_signal_array, tensor_file_pathname) # save extracted channel as file\n",
    "                avg_val = torch.mean(ECG_signal_array)\n",
    "                if nan_counter != 0:\n",
    "                    message = message + f'found {nan_counter} nan-values in file {filename}, age-group {row.iloc[0][config.LABEL_COLUMN_NAME]}'\n",
    "\n",
    "            else:\n",
    "                # should not happen, just in case data was modified\n",
    "                message = message + f'Do not know how to handle device number {device_number}, ignoring entry'\n",
    "                need_to_drop_this_row = True\n",
    "        except Exception as e:\n",
    "            message = message + str(e) # Did not find 0400.dat --> it is indeed missing\n",
    "            need_to_drop_this_row = True\n",
    "\n",
    "    row[config.TENSOR_FILE_COLUMN_NAME] = tensor_file_pathname\n",
    "    return row, need_to_drop_this_row, message, avg_val\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "# read metadata or create it anew\n",
    "if not os.path.exists(config.METADATA_CLEANED_FILE):\n",
    "    metadata = pd.read_csv(config.DATASET_METADATA_FILE)\n",
    "\n",
    "    # change labels according to the bin-merge-dict\n",
    "    for old_label, new_label in config.BIN_MERGE_DICT.items():\n",
    "        metadata.loc[metadata[config.LABEL_COLUMN_NAME] == old_label, config.LABEL_COLUMN_NAME] = new_label\n",
    "\n",
    "    metadata = metadata.dropna() # filters rows with NaN-values\n",
    "    metadata = metadata.reset_index(drop=True) # otherwise .loc[[index] and index will yield different results\n",
    "    need_to_drop_indices = []\n",
    "    metadata[config.TENSOR_FILE_COLUMN_NAME] = ''\n",
    "\n",
    "    if use_parallel:\n",
    "        results = Parallel(n_jobs=os.cpu_count())(delayed(read_and_extract_signal)(metadata.iloc[[index]].copy()) for index, row in metadata.iterrows())\n",
    "    else:\n",
    "        results = []\n",
    "        for index, row in metadata.iterrows():\n",
    "            results.append(read_and_extract_signal(metadata.iloc[[index]]))\n",
    "\n",
    "    # merge results\n",
    "    row_list = []\n",
    "    for row, need_to_drop, message, avg_val in results:\n",
    "        if not message == '': #show all the things that could not be shown during the parallized function calls\n",
    "            print(message)\n",
    "        if not need_to_drop: # drop rows that showed errors\n",
    "            row_list.append(row)\n",
    "            global_avg_val += avg_val\n",
    "\n",
    "    global_avg_val = global_avg_val/len(row_list)\n",
    "    print(f'global average value is {global_avg_val}. Subtracting it from the tensors in the <get-crop>-step')\n",
    "    new_metadata = pd.concat(row_list)\n",
    "    # save the better metadata file\n",
    "    new_metadata.to_csv(config.METADATA_CLEANED_FILE, index=False)\n",
    "    print(f'extracting data & building new metadata file took {time.time()-t1} seconds')\n",
    "    metadata = new_metadata\n",
    "else:\n",
    "    metadata = pd.read_csv(config.METADATA_CLEANED_FILE)\n",
    "    print(f'loading existing metadata file took {time.time()-t1} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T22:24:59.005682784Z",
     "start_time": "2023-06-27T22:24:58.987022609Z"
    }
   },
   "outputs": [],
   "source": [
    "if config.USE_OVERSAMPLING:\n",
    "    # find out how unbalanced the dataset is, so that we know later how to oversample it\n",
    "    # inspired by: https://towardsdatascience.com/demystifying-pytorchs-weightedrandomsampler-by-example-a68aceccb452\n",
    "    class_counts = metadata[config.LABEL_COLUMN_NAME].value_counts()\n",
    "    #print(class_counts)\n",
    "    class_weights = 1/class_counts\n",
    "    sample_weights = [class_weights[i] for i in metadata[config.LABEL_COLUMN_NAME].values]\n",
    "    # each recording now has a weight\n",
    "    # 19 min average per recording = 19min*60s/min, 3 second-crops --> divide by 3 to get the amount of crops needed\n",
    "    global_sampler = WeightedRandomSampler(weights=sample_weights, num_samples=int(config.NUM_CLASSES*class_counts.max()*int(19*60/config.PIECE_LENGTH)), replacement=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T22:24:59.005786804Z",
     "start_time": "2023-06-27T22:24:58.987203119Z"
    }
   },
   "outputs": [],
   "source": [
    "# do train-val-test split\n",
    "not_train_percentage = 1 - (config.SPLIT_ARRAY[0]/np.sum(config.SPLIT_ARRAY))\n",
    "test_val_percentage = config.SPLIT_ARRAY[1]/(config.SPLIT_ARRAY[1] + config.SPLIT_ARRAY[2])\n",
    "\n",
    "train_df, val_test_df = train_test_split(metadata, test_size=not_train_percentage, stratify=metadata[config.LABEL_COLUMN_NAME], random_state=42)\n",
    "val_df, test_df = train_test_split(val_test_df, test_size=test_val_percentage, stratify=val_test_df[config.LABEL_COLUMN_NAME], random_state=42)\n",
    "\n",
    "for idx, df in enumerate([test_df, val_df, train_df]):\n",
    "    # print(df[config.LABEL_COLUMN_NAME].value_counts()) # to check distribution to see if stratify worked\n",
    "    # save file\n",
    "    df.to_csv(os.path.join(set_df_pathnames[idx]), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T22:24:59.005967284Z",
     "start_time": "2023-06-27T22:24:58.987278249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime without dataloader and cropping (as that is not needed for xgboost): 0.07057976722717285\n"
     ]
    }
   ],
   "source": [
    "print(f'Runtime without dataloader and cropping (as that is not needed for xgboost): {time.time()- start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T22:25:23.168324583Z",
     "start_time": "2023-06-27T22:24:58.987381229Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cropping for data of test-set took 35.71535062789917 seconds. It produced 76700 crops.\n",
      "Data cropping for data of val-set took 35.23702692985535 seconds. It produced 81057 crops.\n",
      "Data cropping for data of train-set took 110.7969913482666 seconds. It produced 235409 crops.\n"
     ]
    }
   ],
   "source": [
    "# take ~3minutes\n",
    "# crop data to 3s-pieces, save the individual pieces because otherwise 32 GB RAm are not enough if you later try to load them at once\n",
    "# info: x is later the input-data to the deep learning model. y is the correct label corresponding to x\n",
    "\n",
    "def my_one_hot_encoder(y):\n",
    "    arr = torch.zeros(config.NUM_CLASSES, dtype=torch.float32)\n",
    "    arr[int(y[0])-1] = 1 # -1 as age groups range from 1 to 15, but array from 0 to 14\n",
    "    return arr\n",
    "\n",
    "def get_crop(tensor_path, y, target_folder, id): # crops one file into the pieces we want and saves these pieces with their labels in target_folder\n",
    "    msg = ''\n",
    "    ecg_array = torch.load(tensor_path)#-global_avg_val # read prepared ecg file\n",
    "    filename = Path(tensor_path).stem\n",
    "    ecg_array = np.array(ecg_array, ndmin=2) # first dim is now size 1, second dim has all the data\n",
    "\n",
    "    # do the cropping\n",
    "    cropped_data_pathnames = []\n",
    "    ecg_length_in_s = int(len(ecg_array[0])/config.SAMPLING_RATE)\n",
    "    for i in range(0, ecg_length_in_s-config.PIECE_LENGTH, config.PIECE_LENGTH):\n",
    "        crop_pathname = os.path.join(target_folder, filename + '_label_' + str(y) + '_piece_' + str(i) + '.pt')\n",
    "        if not os.path.exists(crop_pathname):\n",
    "            crop_start = i*config.SAMPLING_RATE\n",
    "            crop_end = (i+config.PIECE_LENGTH)*config.SAMPLING_RATE\n",
    "\n",
    "            if config.ONE_HOT_ENCODE_BINS:\n",
    "                y_encoded = my_one_hot_encoder(y)\n",
    "            else:\n",
    "                y_encoded = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "            my_crop = torch.tensor(ecg_array[:, crop_start:crop_end], dtype=torch.float32)\n",
    "            torch.save([my_crop, y_encoded, id], crop_pathname)\n",
    "            cropped_data_pathnames.append(crop_pathname)\n",
    "        else:\n",
    "            cropped_data_pathnames.append(crop_pathname)\n",
    "        \n",
    "    return cropped_data_pathnames, tensor_path, msg\n",
    "\n",
    "\n",
    "for df_pathname, pieces_folder, set_name in zip(set_df_pathnames, set_pieces_folders, config.SPLIT_NAMES):\n",
    "    df = pd.read_csv(df_pathname)\n",
    "    x_of_part = df[[config.TENSOR_FILE_COLUMN_NAME]].values # the paths to the prepared ecg-files\n",
    "    y_of_part = df[[config.LABEL_COLUMN_NAME]].values # the corresponding labels\n",
    "    id_of_part = df[[\"ID\"]].values # the IDs are needed to that later crops of the same person can be identified\n",
    "\n",
    "    t1 = time.time()\n",
    "    data = Parallel(n_jobs=os.cpu_count())(delayed(get_crop)(x.item(), y, pieces_folder, id) for x,y,id in zip(x_of_part,y_of_part, id_of_part))\n",
    "    for data_pathnames_list, x, msg in data:\n",
    "        if msg != '':\n",
    "            print(msg)\n",
    "\n",
    "    combined_data_pathnames = [data_pathnames_list for data_pathnames_list, x, msg in data if data_pathnames_list != []]    \n",
    "    combined_data_pathnames = list(itertools.chain.from_iterable(combined_data_pathnames)) # flatten the list of lists\n",
    "    t2 = time.time()\n",
    "    print(f'Data cropping for data of {set_name}-set took {t2-t1} seconds. It produced {len(combined_data_pathnames)} crops.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T22:27:24.918287339Z",
     "start_time": "2023-06-27T22:25:23.175901701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating dataloader for test-set all in all took 79.43093466758728 seconds\n",
      "creating dataloader for val-set all in all took 89.8095293045044 seconds\n",
      "shuffled training set\n",
      "creating dataloader for train-set all in all took 266.829030752182 seconds\n"
     ]
    }
   ],
   "source": [
    "# create dataloader\n",
    "# take ~8minutes\n",
    "do_parallel = True # set to False for debugging\n",
    "do_label_check = False # also sets do_parallel to False\n",
    "\n",
    "def load_file(name):\n",
    "    torch_data = torch.load(name) # torch_data[0] contains the time series, torch_data[1] the label (could be one-hot-encoded)\n",
    "    # check if label is valid\n",
    "    if do_label_check:\n",
    "        label = torch_data[1]\n",
    "        if config.ONE_HOT_ENCODE_BINS:\n",
    "            if label.size() == torch.Size([config.NUM_CLASSES]):\n",
    "                label_is_ok = False\n",
    "                num_not_zeros = torch.count_nonzero(label)\n",
    "                if 1 in label:\n",
    "                    if num_not_zeros == 1:\n",
    "                        label_is_ok = True\n",
    "                if not label_is_ok:\n",
    "                    print(f'reporting unexpected label: {label}')\n",
    "            else:\n",
    "                print(f'unexpected tensor format {label.size()}')\n",
    "        else:\n",
    "            if label.size() == torch.Size([1]):\n",
    "                #check if label is between 1 and config.NUM_CLASSES\n",
    "                if not (label[0] >= 1) and (label[0] <= config.NUM_CLASSES):\n",
    "                    print(f'reporting unexpected label: {label[0]}')\n",
    "            else:\n",
    "                print(f'unexpected tensor format {label.size()}')    \n",
    "    return torch_data\n",
    "\n",
    "def get_dataloader(combined_data_pathnames,shuffle=True, sampler=None):\n",
    "    # load the individual pieces\n",
    "    if do_parallel and not do_label_check:\n",
    "        combined_data = Parallel(n_jobs=os.cpu_count())(delayed(load_file)(pathname) for pathname in combined_data_pathnames)\n",
    "    else:\n",
    "        combined_data = []\n",
    "        for pathname in combined_data_pathnames:\n",
    "            combined_data.append(load_file(pathname))\n",
    "\n",
    "    return torch.utils.data.DataLoader(combined_data, batch_size=config.BATCH_SIZE, shuffle=shuffle, drop_last=True, num_workers=config.NUM_WORKERS, sampler=sampler)\n",
    "\n",
    "for df_pathname, pieces_folder, set_name in zip(set_df_pathnames, set_pieces_folders, config.SPLIT_NAMES):\n",
    "    save_pathname = os.path.join(config.DATALOADER_FOLDER, set_name + '_DL.pt')\n",
    "    if not os.path.exists(save_pathname):\n",
    "        combined_data_pathnames = [os.path.join(pieces_folder, f) for f in os.listdir(pieces_folder)] # need full path of each file\n",
    "        t1=time.time()\n",
    "\n",
    "        if set_name == 'train': # only shuffle TRAIN set\n",
    "            if config.USE_OVERSAMPLING: # sampler-option is mutually exclusive with shuffle!\n",
    "                part_loader = get_dataloader(combined_data_pathnames, shuffle=False, sampler=global_sampler)\n",
    "                print('oversampled training set') # only oversample train-set! (val and test-set are imbalanced but its real data)\n",
    "            else:\n",
    "                part_loader = get_dataloader(combined_data_pathnames, shuffle=True)\n",
    "                print('shuffled training set')\n",
    "        else:\n",
    "            part_loader = get_dataloader(combined_data_pathnames, shuffle=False)\n",
    "\n",
    "        # save dataloader\n",
    "        torch.save(part_loader, save_pathname)\n",
    "        print(f'creating dataloader for {set_name}-set all in all took {time.time()-t1} seconds')\n",
    "    else:\n",
    "        print(f'found existing dataloader for {set_name}-set - aboarted creation of a new one')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T22:27:24.918574329Z",
     "start_time": "2023-06-27T22:27:24.913237470Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 181.9015564918518\n"
     ]
    }
   ],
   "source": [
    "# if you run the whole data_preparation_v12.ipynb file completely and for the first time it will take a while\n",
    "# some datapoints:\n",
    "# i5-1240p: ~16 minutes\n",
    "# Ryzen 3700X: ~5 minutes\n",
    "print(f'Runtime: {time.time()- start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
